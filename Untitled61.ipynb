{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTb7axnDzTZOQQLvfuTjIK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamapanThongmee/blog/blob/main/Untitled61.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDeHYQQq31hn"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"\n",
        "SPX Market Breadth Dashboard - Robust Version (Fix blank charts)\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from datetime import timedelta, date\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# -------------------------\n",
        "# Page\n",
        "# -------------------------\n",
        "st.set_page_config(page_title=\"SPX Dashboard\", layout=\"wide\")\n",
        "\n",
        "SHEET_ID = \"1faOXwIk7uR51IIeAMrrRPdorRsO7iJ3PDPn-mk5vc24\"\n",
        "GID = \"564353266\"\n",
        "\n",
        "URL_PRIMARY  = f\"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv&gid={GID}\"\n",
        "URL_FALLBACK = f\"https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&gid={GID}\"\n",
        "\n",
        "st.title(\"ðŸ“ˆ SPX Dashboard\")\n",
        "\n",
        "# -------------------------\n",
        "# Helpers\n",
        "# -------------------------\n",
        "def _looks_like_html(text: str) -> bool:\n",
        "    t = (text or \"\").lstrip().lower()\n",
        "    return t.startswith(\"<!doctype html\") or t.startswith(\"<html\") or (\"servicelogin\" in t)\n",
        "\n",
        "def _clean_numeric_series(s: pd.Series) -> pd.Series:\n",
        "    s = s.astype(str).str.strip()\n",
        "    s = s.replace({\"nan\": \"\", \"None\": \"\", \"null\": \"\"})\n",
        "    s = (\n",
        "        s.str.replace(\",\", \"\", regex=False)\n",
        "         .str.replace(\"%\", \"\", regex=False)\n",
        "         .str.replace(\"âˆ’\", \"-\", regex=False)   # unicode minus\n",
        "         .str.replace(\"â€”\", \"-\", regex=False)\n",
        "    )\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "def _normalize_percent(s: pd.Series) -> pd.Series:\n",
        "    x = _clean_numeric_series(s)\n",
        "    mx = x.max(skipna=True)\n",
        "    if pd.notna(mx) and mx <= 1.5:\n",
        "        x = x * 100.0\n",
        "    return x\n",
        "\n",
        "def _pick_col(df: pd.DataFrame, candidates: list[str]) -> str | None:\n",
        "    cols = {str(c).strip().lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        key = cand.strip().lower()\n",
        "        if key in cols:\n",
        "            return cols[key]\n",
        "    return None\n",
        "\n",
        "def _to_naive_normalized_dt(s: pd.Series) -> pd.Series:\n",
        "    dt = pd.to_datetime(s, errors=\"coerce\")\n",
        "    # remove timezone if any (safe)\n",
        "    try:\n",
        "        if getattr(dt.dt, \"tz\", None) is not None:\n",
        "            dt = dt.dt.tz_convert(None)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # normalize to midnight so comparisons match\n",
        "    dt = dt.dt.normalize()\n",
        "    return dt\n",
        "\n",
        "def _build_standard_df(raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = raw.copy()\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "\n",
        "    # name-based mapping\n",
        "    col_date  = _pick_col(df, [\"Date\", \"Datetime\", \"Time\", \"timestamp\"])\n",
        "    col_open  = _pick_col(df, [\"Open\"])\n",
        "    col_high  = _pick_col(df, [\"High\"])\n",
        "    col_low   = _pick_col(df, [\"Low\"])\n",
        "    col_close = _pick_col(df, [\"Close\"])\n",
        "\n",
        "    col_ma20  = _pick_col(df, [\"MA20\"])\n",
        "    col_ma50  = _pick_col(df, [\"MA50\"])\n",
        "    col_ma200 = _pick_col(df, [\"MA200\"])\n",
        "\n",
        "    col_above = _pick_col(df, [\"Percentage_Above_Both\", \"PctAbove\", \"% Above Both\", \"AboveBoth\"])\n",
        "    col_below = _pick_col(df, [\"Percentage_Below_Both\", \"PctBelow\", \"% Below Both\", \"BelowBoth\"])\n",
        "\n",
        "    # positional fallback (A..S style)\n",
        "    if not all([col_date, col_open, col_high, col_low, col_close]):\n",
        "        def try_positional(offset: int = 0) -> dict:\n",
        "            if df.shape[1] < 19 + offset:\n",
        "                return {}\n",
        "            cols = df.columns.tolist()\n",
        "            return {\n",
        "                \"Date\": cols[0 + offset],\n",
        "                \"Open\": cols[1 + offset],\n",
        "                \"High\": cols[2 + offset],\n",
        "                \"Low\":  cols[3 + offset],\n",
        "                \"Close\":cols[4 + offset],\n",
        "                \"MA20\": cols[11 + offset],\n",
        "                \"MA50\": cols[12 + offset],\n",
        "                \"MA200\":cols[14 + offset],\n",
        "                \"PctAbove\": cols[15 + offset],\n",
        "                \"PctBelow\": cols[18 + offset],\n",
        "            }\n",
        "\n",
        "        mapping = try_positional(0) or try_positional(1)\n",
        "        if not mapping:\n",
        "            raise ValueError(f\"Cannot map columns. Found {df.shape[1]} columns: {df.columns.tolist()}\")\n",
        "\n",
        "        out = pd.DataFrame({\n",
        "            \"Date\": df[mapping[\"Date\"]],\n",
        "            \"Open\": df[mapping[\"Open\"]],\n",
        "            \"High\": df[mapping[\"High\"]],\n",
        "            \"Low\":  df[mapping[\"Low\"]],\n",
        "            \"Close\":df[mapping[\"Close\"]],\n",
        "            \"MA20\": df[mapping[\"MA20\"]],\n",
        "            \"MA50\": df[mapping[\"MA50\"]],\n",
        "            \"MA200\":df[mapping[\"MA200\"]],\n",
        "            \"PctAbove\": df[mapping[\"PctAbove\"]],\n",
        "            \"PctBelow\": df[mapping[\"PctBelow\"]],\n",
        "        })\n",
        "    else:\n",
        "        out = pd.DataFrame({\n",
        "            \"Date\": df[col_date],\n",
        "            \"Open\": df[col_open],\n",
        "            \"High\": df[col_high],\n",
        "            \"Low\":  df[col_low],\n",
        "            \"Close\":df[col_close],\n",
        "            \"MA20\": df[col_ma20] if col_ma20 else None,\n",
        "            \"MA50\": df[col_ma50] if col_ma50 else None,\n",
        "            \"MA200\":df[col_ma200] if col_ma200 else None,\n",
        "            \"PctAbove\": df[col_above] if col_above else None,\n",
        "            \"PctBelow\": df[col_below] if col_below else None,\n",
        "        })\n",
        "\n",
        "    # parse dates robustly (normalize)\n",
        "    out[\"Date\"] = _to_naive_normalized_dt(out[\"Date\"])\n",
        "    out = out.dropna(subset=[\"Date\"]).sort_values(\"Date\")\n",
        "\n",
        "    for c in [\"Open\", \"High\", \"Low\", \"Close\", \"MA20\", \"MA50\", \"MA200\"]:\n",
        "        if c in out.columns:\n",
        "            out[c] = _clean_numeric_series(out[c])\n",
        "\n",
        "    for c in [\"PctAbove\", \"PctBelow\"]:\n",
        "        if c in out.columns:\n",
        "            out[c] = _normalize_percent(out[c])\n",
        "\n",
        "    return out\n",
        "\n",
        "def make_rangebreaks(dff: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Safe rangebreaks:\n",
        "    - always skip weekends\n",
        "    - additionally skip missing BUSINESS days only (holidays)\n",
        "    \"\"\"\n",
        "    if dff.empty:\n",
        "        return [dict(bounds=[\"sat\", \"mon\"])]\n",
        "\n",
        "    # âœ… correct for Series\n",
        "    obs = pd.to_datetime(dff[\"Date\"], errors=\"coerce\").dt.normalize()\n",
        "    obs = obs.dropna()\n",
        "    if obs.empty:\n",
        "        return [dict(bounds=[\"sat\", \"mon\"])]\n",
        "\n",
        "    obs_set = set(obs.unique())\n",
        "    bdays = pd.date_range(obs.min(), obs.max(), freq=\"B\")\n",
        "    missing_bdays = [d for d in bdays if d not in obs_set]\n",
        "\n",
        "    rbs = [dict(bounds=[\"sat\", \"mon\"])]\n",
        "    if missing_bdays:\n",
        "        rbs.append(dict(values=missing_bdays))\n",
        "    return rbs\n",
        "\n",
        "@st.cache_data(ttl=300, show_spinner=False)\n",
        "def load_sheet_df(url_primary: str, url_fallback: str) -> tuple[pd.DataFrame, str]:\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    for url in [url_primary, url_fallback]:\n",
        "        r = requests.get(url, headers=headers, timeout=20)\n",
        "        txt = r.text or \"\"\n",
        "        if _looks_like_html(txt):\n",
        "            continue\n",
        "        df = pd.read_csv(StringIO(txt), dtype=str)\n",
        "        return df, url\n",
        "    raise ValueError(\"Google Sheet did not return CSV (private/not published or wrong GID).\")\n",
        "\n",
        "# -------------------------\n",
        "# Controls\n",
        "# -------------------------\n",
        "c1, c2, c3, c4 = st.columns([1, 1.5, 3, 1.5])\n",
        "\n",
        "with c1:\n",
        "    if st.button(\"ðŸ”„ Refresh data\", use_container_width=True):\n",
        "        st.cache_data.clear()\n",
        "        st.rerun()\n",
        "\n",
        "with c2:\n",
        "    months_to_show = st.selectbox(\"Default window\", [3, 6, 12, 24], index=1)\n",
        "\n",
        "with c4:\n",
        "    disable_breaks = st.checkbox(\"Disable rangebreaks (debug)\", value=False)\n",
        "\n",
        "# -------------------------\n",
        "# Load\n",
        "# -------------------------\n",
        "try:\n",
        "    raw_df, used_url = load_sheet_df(URL_PRIMARY, URL_FALLBACK)\n",
        "except Exception as e:\n",
        "    st.error(f\"Load failed: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    df = _build_standard_df(raw_df)\n",
        "except Exception as e:\n",
        "    st.error(f\"Parse/mapping failed: {e}\")\n",
        "    with st.expander(\"Debug: raw columns + preview\"):\n",
        "        st.write(raw_df.columns.tolist())\n",
        "        st.write(raw_df.head(10))\n",
        "    st.stop()\n",
        "\n",
        "if df.empty:\n",
        "    st.warning(\"No valid rows after parsing Date. Check your Date column format.\")\n",
        "    with st.expander(\"Debug: raw preview\"):\n",
        "        st.write(raw_df.head(20))\n",
        "    st.stop()\n",
        "\n",
        "max_date = df[\"Date\"].max()\n",
        "default_start = (max_date - timedelta(days=30 * int(months_to_show))).date()\n",
        "default_end = max_date.date()\n",
        "\n",
        "with c3:\n",
        "    start_d, end_d = st.date_input(\n",
        "        \"Date range\",\n",
        "        value=(default_start, default_end),\n",
        "        min_value=df[\"Date\"].min().date(),\n",
        "        max_value=df[\"Date\"].max().date(),\n",
        "    )\n",
        "    if isinstance(start_d, date) and isinstance(end_d, date) and start_d > end_d:\n",
        "        start_d, end_d = end_d, start_d\n",
        "\n",
        "mask = (df[\"Date\"].dt.date >= start_d) & (df[\"Date\"].dt.date <= end_d)\n",
        "dff = df.loc[mask].copy()\n",
        "\n",
        "st.markdown(\"---\")\n",
        "# st.write(f\"Using: `{used_url}`\")\n",
        "# st.write(f\"Showing: **{start_d} â†’ {end_d}** | Rows: **{len(dff):,}**\")\n",
        "st.write(f\"Showing: **{start_d} â†’ {end_d}**\") # | Rows: **{len(dff):,}**\")\n",
        "\n",
        "if dff.empty:\n",
        "    st.warning(\"No data in the selected date range.\")\n",
        "    st.stop()\n",
        "\n",
        "needed_ohlc = dff[[\"Open\", \"High\", \"Low\", \"Close\"]].notna().all(axis=1).sum()\n",
        "if needed_ohlc == 0:\n",
        "    st.error(\"OHLC columns are not numeric (all NaN after cleaning).\")\n",
        "    with st.expander(\"Debug: cleaned OHLC sample\"):\n",
        "        st.write(dff[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\"]].head(30))\n",
        "    st.stop()\n",
        "\n",
        "rangebreaks = [] if disable_breaks else make_rangebreaks(dff)\n",
        "\n",
        "# -------------------------\n",
        "# Charts\n",
        "# -------------------------\n",
        "st.subheader(\"ðŸ“ˆ S&P 500 Index\")\n",
        "fig1 = go.Figure(\n",
        "    go.Candlestick(\n",
        "        x=dff[\"Date\"],\n",
        "        open=dff[\"Open\"],\n",
        "        high=dff[\"High\"],\n",
        "        low=dff[\"Low\"],\n",
        "        close=dff[\"Close\"],\n",
        "        increasing_line_color=\"#26a69a\",\n",
        "        decreasing_line_color=\"#ef5350\",\n",
        "    )\n",
        ")\n",
        "if rangebreaks:\n",
        "    fig1.update_xaxes(rangebreaks=rangebreaks)\n",
        "fig1.update_layout(height=450, template=\"plotly_dark\", xaxis_rangeslider_visible=False)\n",
        "st.plotly_chart(fig1, use_container_width=True)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.subheader(\"ðŸ“Š Market Breadth Analysis\")\n",
        "tab1, tab2 = st.tabs([\"ðŸ“Š Moving Averages\", \"ðŸ“ˆ Percentage Distribution\"])\n",
        "\n",
        "with tab1:\n",
        "    fig2 = go.Figure()\n",
        "    if \"MA20\" in dff.columns and dff[\"MA20\"].notna().any():\n",
        "        fig2.add_trace(go.Scatter(x=dff[\"Date\"], y=dff[\"MA20\"], name=\"MA20\", line=dict(width=1.5)))\n",
        "    if \"MA50\" in dff.columns and dff[\"MA50\"].notna().any():\n",
        "        fig2.add_trace(go.Scatter(x=dff[\"Date\"], y=dff[\"MA50\"], name=\"MA50\", line=dict(width=2)))\n",
        "    if \"MA200\" in dff.columns and dff[\"MA200\"].notna().any():\n",
        "        fig2.add_trace(go.Scatter(x=dff[\"Date\"], y=dff[\"MA200\"], name=\"MA200\", line=dict(width=2.5)))\n",
        "\n",
        "    if rangebreaks:\n",
        "        fig2.update_xaxes(rangebreaks=rangebreaks)\n",
        "    fig2.update_layout(\n",
        "        height=400,\n",
        "        template=\"plotly_dark\",\n",
        "        hovermode=\"x unified\",\n",
        "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "    )\n",
        "    st.plotly_chart(fig2, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    fig3 = go.Figure()\n",
        "\n",
        "    if \"PctAbove\" in dff.columns and dff[\"PctAbove\"].notna().any():\n",
        "        fig3.add_trace(\n",
        "            go.Scatter(\n",
        "                x=dff[\"Date\"], y=dff[\"PctAbove\"],\n",
        "                name=\"% Above Both\",\n",
        "                fill=\"tozeroy\",\n",
        "                line=dict(width=1.5),\n",
        "                fillcolor=\"rgba(0, 255, 0, 0.2)\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if \"PctBelow\" in dff.columns and dff[\"PctBelow\"].notna().any():\n",
        "        fig3.add_trace(\n",
        "            go.Scatter(\n",
        "                x=dff[\"Date\"], y=dff[\"PctBelow\"],\n",
        "                name=\"% Below Both\",\n",
        "                fill=\"tozeroy\",\n",
        "                line=dict(width=1.5),\n",
        "                fillcolor=\"rgba(255, 0, 0, 0.2)\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if rangebreaks:\n",
        "        fig3.update_xaxes(rangebreaks=rangebreaks)\n",
        "    fig3.update_layout(\n",
        "        height=400,\n",
        "        template=\"plotly_dark\",\n",
        "        hovermode=\"x unified\",\n",
        "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
        "        yaxis_title=\"Percent\",\n",
        "    )\n",
        "    st.plotly_chart(fig3, use_container_width=True)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(f\"ðŸ“Š Dashboard | {len(dff):,} points | {dff['Date'].min().date()} to {dff['Date'].max().date()}\")"
      ]
    }
  ]
}